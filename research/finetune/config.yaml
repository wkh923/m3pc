pretrain_model_path: /home/unitree/mtm/outputs/mtm_mae/2023-10-23_15-29-02/model_140010.pt
pretrain_critic1_path: /home/unitree/mtm/research/Implicit-Q-Learning/trained_models/IQLhopper-medium-v2critic1.pt
pretrain_critic2_path: /home/unitree/mtm/research/Implicit-Q-Learning/trained_models/IQLhopper-medium-v2critic2.pt
pretrain_value_path: /home/unitree/mtm/research/Implicit-Q-Learning/trained_models/IQLhopper-medium-v2value.pt
pretrain_args:
    env_name: hopper-medium-v2
    traj_length: 8

pretrain_dataset:
    _target_: research.mtm.datasets.d4rl_ds.get_datasets
    seq_steps: ???
    env_name: hopper-medium-v2
    use_reward: true
    seed: 0
    discount: 1.5
    train_val_split: 0.95

tokenizers:
    states:
      _target_: research.mtm.tokenizers.continuous.ContinuousTokenizer.create
    actions:
      _target_: research.mtm.tokenizers.continuous_binned.ContinuousBinnedTokenizer.create
    returns:
      _target_: research.mtm.tokenizers.continuous.ContinuousTokenizer.create
    rewards:
      _target_: research.mtm.tokenizers.continuous.ContinuousTokenizer.create


model_config:
    _target_: research.mtm.models.mtm_model.MTMConfig
    norm: none
    n_embd: 512
    n_enc_layer: 2
    n_dec_layer: 1
    n_head: 4
    dropout: 0.1
    loss_keys: null
    latent_dim: null

finetune_args: 
    _target_: research.finetune.finetune.RunConfig
    discount: 0.99
    seed: 1000
    batch_size: 1024
    warmup_steps: 1000
    num_train_steps: 90000
    learning_rate: 1e-5
    critic_lr: 3e-4
    v_lr: 3e-4
    weight_decay: 5e-3
    device: cuda
    use_masked_loss: False
    loss_weight: {"actions":  1.0, "states": 1.0, "returns": 1.0, "rewards": 1.0}
    
    #train
    print_every: 50
    log_every: 100
    eval_every: 2000
    save_every: 2000
    
    # #debug
    # print_every: 1
    # log_every: 1
    # eval_every: 1
    # save_every: 1
    
    #cem 
    n_iter: 3
    n_rsamples: 512
    n_policy_samples: 512
    top_k: 128
    temperature: 0.5

    #replay buffer
    buffer_size: 1000
    pretrain_discount: 1.5
    num_updates_per_online_rollout: 100
    clip_min: -1.0
    clip_max: 1.0
    action_noise_std: 0.2
    tau: 5e-3

    critic_hidden_size: 256


wandb:
    project: d4rl_finetune
    entity: wkh923
    resume: null

hydra:
    job:
        name: finetune
        chdir: True